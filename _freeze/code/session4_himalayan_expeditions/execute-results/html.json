{
  "hash": "69d56ddfa31505cac3567c0ecaf52be2",
  "result": {
    "markdown": "---\ntitle: \"Week 4 exercises: Himalayan expeditions\"\nauthor: \"insert your name here\"\nformat: \n  html:\n    self-contained: true\n    toc: true\n---\n\n\n## Background\n\nFor our week 4 workshop, we will draw on a new data set, thus giving you the opportunity to practise and consolidate what we have covered over the past few weeks.\nThe data set is on Himalayan climbing expeditions and it is drawn from a [\"Tidy Tuesday\" challenge from 2020](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-22/readme.md). #TidyTuesday is a \"weekly social data project\", as a part of which participants around the world practice their data science skills in R by applying them to a new data set each week. See the [Tidy Tuesday website and repository](https://github.com/rfordatascience/tidytuesday) for further details.\n\nIn the week 4 workshop, we will first go through how to load the data set.\nYou will then have time to explore the questions below.\nFor each question, please provide a brief answer as well as the code that you used to get to your answer.\nWhen creating plots, add appropriate titles and axis labels.\n\nPlease upload the completed (and rendered) document in fulfilment of your week 4 exercises.\n\n## Load packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n:::\n\n\n\n## Load data on Himalayan climbing expeditions\n\nDon't worry about the details of the below code for now. In brief, it uses the function `read_csv()` to read in some data from files that have been made available on the Tidytuesday website. We will see how to read in our own data in week 5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmembers <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/members.csv')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 76519 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): expedition_id, member_id, peak_id, peak_name, season, sex, citizen...\ndbl  (5): year, age, highpoint_metres, death_height_metres, injury_height_me...\nlgl  (6): hired, success, solo, oxygen_used, died, injured\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nexpeditions <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/expeditions.csv')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 10364 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): expedition_id, peak_id, peak_name, season, termination_reason, tre...\ndbl  (6): year, highpoint_metres, members, member_deaths, hired_staff, hired...\nlgl  (1): oxygen_used\ndate (3): basecamp_date, highpoint_date, termination_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\npeaks <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-22/peaks.csv')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 468 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): peak_id, peak_name, peak_alternative_name, climbing_status, first_a...\ndbl (2): height_metres, first_ascent_year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n\n## Basic exploration of peaks and their climbing status\n\nWe start by using the `peaks` data. \n\n1. Plot a histogram of the height of the Himalayan peaks in the data set. Remember to adjust the binwidth parameter. Which value did you choose and why? Within which range of heights (roughly) do we find the most peaks?\n\n2. How many peaks in the data set have been climbed and how many haven't?\n\n3. Does the distribution of heights differ between the peaks that have been climbed and those that haven't? Use an appropriate visualisation to address this question.\n\n4. How did the number of first ascents change over time? Use a line graph to chart the number of first ascents from year to year. (Hint: the first time you do this, you will likely see a very strange-looking graph. Use the `summary()` function to have a look at the values of `first_ascent_year` and have a think about how you could fix the problem that you encounter before replotting.)\n\n5. a. Which country (or countries) has/have recorded the highest number of first ascents?\n\nb. To get rid of the missing values in the data frame that your response to a. likely produced, use `filter(!is.na(first_ascent_country))` in addition to the other computations that you undertook. Save the resulting data frame as a new object.\n\nc. Use your newly created data frame from b to visualise the number of first ascents per country for all countries with at least 10 first ascents. Do this using a column graph.\n\nd. Try flipping your column graph from c to a horizontal layout by switching what you put on the x and y axes.\n\ne. One final modification: you can sort the columns to be ordered from high to low (for horizontal bars) by using `reorder(first_ascent_country,n)`. Try plugging this into your y-axis aesthetic! If you want the reverse order, use `-n` instead.\n\n## Expeditions\n\nLet's now look more closely at expeditions by using the `expeditions` data.\n\n### How deadly are individual peaks?\n\nThe columns `member_deaths` and `hired_staff_deaths` encode the number of deaths (if any) per expedition.\n\n6. a. To look at how deadly individual peaks are, first create a new column which encodes the total number of deaths per expedition, then compute a summary statistic for the overall number of deaths per mountain. (Hint: there is a function called `sum()` that you can apply in the same way as `mean()`, `sd()` etc.). Sort in descending order of deaths and save as a new object. Which mountain is the deadliest according to your calculations?\n\nb. Use the new data frame created in a. to plot a horizontal column graph of the top 10 deadly mountains. As for question 5, sort the columns so that the deadliest mountain is at the top.\n\n### Which season has the highest likelihood of success? (optional)\n\n7. Use a boxplot to compare the highpoint reached by expeditions per season. Filter out the \"unhelpful\" values (you will know which ones I mean when you create the basic plot). Note that you can use `filter()` to only keep rows that are not equal to a particular value by using != rather than ==, so to eliminate the value \"red\" from a column called \"colour\", for example, you could use `filter(colour != \"red\")`. Based on this graph, which season would you choose if you were opting for a Himalayan climbing expedition?\n\n8. a. Examine the top reasons for expedition termination by looking at the `termination_reason` column. (Hint: `count` will be very useful here ...) \n\nb. Drawing on your answer to a, isolate the number of expeditions that were terminated because they succeeded in climbing the main peak and count how many of these there were per season and year. (Consider restricting the range of years that you look at to make the graph a bit clearer.) What patterns can you see?\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}